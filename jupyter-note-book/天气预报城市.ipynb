{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbe76c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取数据...........................\n",
      "爬取完毕！！\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "\n",
    "def get_web(url):\n",
    "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36 Edg/91.0.864.59\"}\n",
    "    res = requests.get(url, headers=header, timeout=5)\n",
    "    # print(res.encoding)\n",
    "    content = res.text.encode('ISO-8859-1')\n",
    "    return content\n",
    "\n",
    "\n",
    "def parse_content(content):\n",
    "    soup = bs4.BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    '''\n",
    "    存放天气情况\n",
    "    '''\n",
    "    list_weather = []\n",
    "    weather_list = soup.find_all('p', class_='wea')\n",
    "    for i in weather_list:\n",
    "        list_weather.append(i.text)\n",
    "\n",
    "    '''\n",
    "    存放日期\n",
    "    '''\n",
    "    list_day = []\n",
    "    i = 0\n",
    "    day_list = soup.find_all('h1')\n",
    "    for each in day_list:\n",
    "        if i <= 6:\n",
    "            list_day.append(each.text.strip())\n",
    "            i += 1\n",
    "    # print(list_day)\n",
    "\n",
    "    '''\n",
    "    存放温度：最高温度和最低温度\n",
    "    '''\n",
    "    tem_list = soup.find_all('p', class_='tem')\n",
    "    i = 0\n",
    "    list_tem = []\n",
    "    for each in tem_list:\n",
    "        if i == 0:\n",
    "            list_tem.append(each.i.text)\n",
    "            i += 1\n",
    "        elif i > 0:\n",
    "            list_tem.append([each.span.text, each.i.text])\n",
    "            i += 1\n",
    "    # print(list_tem)\n",
    "\n",
    "    '''\n",
    "    存放风力\n",
    "    '''\n",
    "    list_wind = []\n",
    "    wind_list = soup.find_all('p', class_='win')\n",
    "    for each in wind_list:\n",
    "        list_wind.append(each.i.text.strip())\n",
    "    # print(list_wind)\n",
    "    return list_day, list_weather, list_tem, list_wind\n",
    "\n",
    "\n",
    "def get_content(url):\n",
    "    content = get_web(url)\n",
    "    day, weather, tem, wind = parse_content(content)\n",
    "    item = 0\n",
    "    with open('weather.txt', 'a+', encoding='utf-8') as file:\n",
    "        for i in range(0, 7):\n",
    "            if item == 0:\n",
    "                file.write(day[i]+':\\t')\n",
    "                file.write(weather[i]+'\\t')\n",
    "                file.write(\"今日气温：\"+tem[i]+'\\t')\n",
    "                file.write(\"风力：\"+wind[i]+'\\t')\n",
    "                file.write('\\n')\n",
    "                item += 1\n",
    "            elif item > 0:\n",
    "                file.write(day[i]+':\\t')\n",
    "                file.write(weather[i] + '\\t')\n",
    "                file.write(\"最高气温：\"+tem[i][0]+'\\t')\n",
    "                file.write(\"最低气温：\"+tem[i][1] + '\\t')\n",
    "                file.write(\"风力：\"+wind[i]+'\\t')\n",
    "                file.write('\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"http://www.weather.com.cn/weather/101010100.shtml\"\n",
    "    print(\"正在爬取数据...........................\")\n",
    "    get_content(url)\n",
    "    print(\"爬取完毕！！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
